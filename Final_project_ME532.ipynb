{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLEASE change the PATH of dataset, when you run this code!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLEASE change the PATH of dataset, when you run this code!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CIFAR-10 training set:\n",
      " - np.shape(images)     (50000, 32, 32, 3)\n",
      " - np.shape(labels)     (50000,)\n"
     ]
    }
   ],
   "source": [
    "##### PLEASE change the PATH of dataset, when you run this code!!!!!!\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the unzipped CIFAR data\n",
    "data_dir = Path(\"/Users/mmwr/downloads/cifar-10-batches-py/\")\n",
    "\n",
    "# Unpickle function provided by the CIFAR hosts\n",
    "def unpickle(file):\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "images, labels = [], []\n",
    "for batch in data_dir.glob(\"data_batch_*\"):\n",
    "    batch_data = unpickle(batch)\n",
    "    for i, flat_im in enumerate(batch_data[b\"data\"]):\n",
    "        im_channels = []\n",
    "        # Each image is flattened, with channels in order of R, G, B\n",
    "        for j in range(3):\n",
    "            im_channels.append(\n",
    "                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))\n",
    "            )\n",
    "        # Reconstruct the original image\n",
    "        images.append(np.dstack((im_channels)))\n",
    "        # Save the label\n",
    "        labels.append(batch_data[b\"labels\"][i])\n",
    "\n",
    "print(\"Loaded CIFAR-10 training set:\")\n",
    "print(f\" - np.shape(images)     {np.shape(images)}\")\n",
    "print(f\" - np.shape(labels)     {np.shape(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfBUlEQVR4nO2da2yd15We33VuPDwkJVKiLpREXSxbvta3qI6nDtzUbgM3CJBk2gSTHwMDDcbzY4I2wPSHkQJN+i8tmgxSoAigTIzxFJlMgiZpPAOjHtdtkmbixpYd23IsO5ZtWZZIkRIp3s79svqDx6js7HeTFslDdfb7AATJvbi/b519vnU+nv2etZa5O4QQf/fJbLYDQojeoGAXIhEU7EIkgoJdiERQsAuRCAp2IRIht5bJZvYAgG8AyAL4U3f/auzvh4pFHx0aCto6nYgEaGS4kKdTWhn+OlbKkgMCaFQq1DZXrgbH21fg+womWMT/bI4/bVkyrRhZq6HBErXFpNlWu0NtlskGx6v1Bp2zuFimtug6RmxZYsxE5nRicnRMqY5dBhEnO2Riiy8vjJyrUq+j0WwGT3bFwW5mWQD/GcA/AXAWwLNm9pi7v8LmjA4N4cu/++mgrVrmF0E2F76CbXyMzpkr9VPbrVsL1HbmpV9R2189/UL4XPUmnZNl0Yf4BZDvK1Lbth2j1LalP3y+6/bvoHM+es9d1NZq8sd2cX6J2vJDI8Hxk6fepnOe+snT1AZyDQBAX57btubDL3KFXJvOaUQecyscR8s4j86+bB+1VTx87V+q8VePDHHxf7/4Mp9DLStzF4BT7v6muzcA/CWAT67heEKIDWQtwb4XwDuX/X62OyaEuApZS7CH/p/5rf87zOwhMztuZscXa7U1nE4IsRbWEuxnAYxf9vs+ABPv/yN3P+buR9396FCRvw8VQmwsawn2ZwFcZ2aHzKwA4PcAPLY+bgkh1psr3o1395aZfQHAE1iW3h5x91/H5rSadVw691bYkYiMk8+FdyXPeZ3Oeb3Kd1RvvfEaaus0+DF3jYZ3wfsj54rpMbHd+Eqd+zE/e4naliy8y1yvhWVDALjtzg9TW7PC33pdnOF+7CqG1ZBOY4HO6e/ja9UBvz52Dg1S2y3XXBscvzB9js6pVhepbWmJKxDIcHmzL9eitj27twbHm4WddM6pV06HXYhoimvS2d39cQCPr+UYQojeoE/QCZEICnYhEkHBLkQiKNiFSAQFuxCJsKbd+A9Ko5PBW7VwQkClOk/nFYzIP+2wZAEAGePJLhffnqK25ybOUtur02GpyetcVonJa8XIh4yaLZ6ogUhGXLE/vL5zVS5dPXPidWob287XuN6K5e2FZbS+yBWXz8dS0bjp+sOHqe3g/gPB8eEhnul3fvI0d6PJpcjBEZ6Y1c7zxKxSX1jO2zPKJcV3smH/zfi1oTu7EImgYBciERTsQiSCgl2IRFCwC5EIPd2N7xhQJfXfZjN899na4aSQ7ZFabINbwmWRAKBW5jv/c4s8AWWhFk548Yjv7Ta3ZcnxACAXex1u8oSRMknkGYzUVXvmxZeo7ci14UQSALjh8H5qyxXCu8UHD/Kd83KHJ5JMTV6gtoVFnuSD4kBw+Oi9t9IpLzz7U2qrtrjystjkO/wzZX49bquGd/j3ZnlCTm0pHEeRyli6swuRCgp2IRJBwS5EIijYhUgEBbsQiaBgFyIReiq9GVros9mgbazEJY1hhCWZbSM8ueAt57LFQH+kcwfrqwOgZOHlag7wbh/NFpfXapE6c+3I63B/iUs8hb7wWu2OdM/Zs2+c2i4u8cSP8wtc8vrwh8NdZmanztM5v/vP7qG2x//6CWp7+hf/h9r233JncPy+Wz9E57xx7k1qe+tvn6W2+Ua4tRkALEV6Od3498M+Vpu8xt/oaDiJKpfjCWC6swuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIR1iS9mdlpAIsA2gBa7n40+vcZQ2EgfMprhnirm0MenrO1EGkUOc9ryZWGuVRWLlSorZMPZ7AdvT0snQDArp38cb156hS1vXOGtyfKZHl2mLfCUlkxkpn3Ox/m/l/gy4FnfvoTanvttXBGXLsaOeAAzwybK3OZcqnJ71mnJmeC4+VOls4pt/jxpue4H/Uirxl33QHecmx4157g+IWZsO8AcN99NwfHn3juf9A566Gz/yN3v7gOxxFCbCD6N16IRFhrsDuAvzGz58zsofVwSAixMaz13/h73H3CzHYCeNLMXnX3n13+B90XgYcAYIjUNBdCbDxrurO7+0T3+zSAHwH4rQ9Eu/sxdz/q7kf7yee2hRAbzxUHu5kNmNnQuz8D+BiAl9fLMSHE+rKWf+N3AfhRt71RDsBfuPt/j03ouGGpEb67b82GCwMCQPNiOPvnnTkuT33kthuordooU9veSMG+YimcEXf3MPf9ph2j1Fbp8Ay7i338LU9lnmdDtRvh8VyDZwEeOPMWtfXP8WzEbTuGqa358q+C4zHZ8OlXTlLbaxMT1FZrcTns3JmwBDs9wwtY3nXH3dR2YJhnCP6nv/hv1Nao8my/554Ni1lTU2/QOXfeH76+sx2+Flcc7O7+JoDbrnS+EKK3SHoTIhEU7EIkgoJdiERQsAuRCAp2IRKhpwUnc8hgRzacqbYXPAtpy5ZwIb8XLvHMtkt13s/twG5efPGfTx+itvxCWLLb/jr3o++NSWprd3gxyoPhVl7LfrS5MZMLr2/buORVf+Z5atsakbU6o1xybLMCiws8+25LlmeN1ctcLt3GLx2UPFwUc+H823TO3huPUNvQAM+0vOvwXmqbnieaKIDzS+FMwEolXJwVAN58/fXgeD1SxFR3diESQcEuRCIo2IVIBAW7EImgYBciEXq6G1/MZnDDULh10cAMr2yVzYR3do/s20fnLE7xRAc4383eG2v/VAjPy0Z2TS2S7ML3Z4F6JvI6XOBJMnkPny8XaT+Uz3BVoDnEt7q9wnd+W/WwH23wtd+V4StyXz/f+W8Yb3nU3rMrOF48fZrOqfDDAUQZAoCbb7iW2sYq/LGNNcPJRkcOh2vTAcC1o2HlovjEz+kc3dmFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCD2V3trNOmYn3gza6i0uyVSzYdmospUnTvRXuJxUO8lre7WzPFGjRVpXZbJcVumLSF4GnlTRisiD7Q4/pufDCS9cAIzbcjt526KhOX6vqJGH1jjAWzyNtJaobaDG17gVqZO3NB1OiKpM/C2dM3n8RWrbcjNPkpk5z+XeRmkbtbXCuTqozPBagwv58Hq023wtdGcXIhEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIqwovZnZIwA+AWDa3W/pjm0D8D0ABwGcBvBZd+c6QZdWu42Zpbmg7Z1yjc/rhOWEgu2mc0ojvO3STJW3Qtqd5Rll/bXwa2N7gct89Qa3YZT7OHCEZ1DVIhLV0sWF4Hhfh0t52UjdsvoFvlbo4zKaDYdl0Vwkq7CzwK+B/pu5BIgCl2BL02Fdq3yOtw6be/UUtXXOTFHb0DaeETc7zOXSmfPh53Nymtc2PFQI11Fst/j1tpo7+58BeOB9Yw8DeMrdrwPwVPd3IcRVzIrB3u23/v6E7U8CeLT786MAPrXOfgkh1pkrfc++y90nAaD7fef6uSSE2Ag2fIPOzB4ys+NmdrzS4h9FFUJsLFca7FNmNgYA3e/T7A/d/Zi7H3X3o6VcpJq/EGJDudJgfwzAg92fHwTw4/VxRwixUaxGevsugI8CGDWzswC+DOCrAL5vZp8HcAbAZ1ZzspZ3cKkWllfOV7ic1CRtl0Z37aBzfJxvI/SNcImkb4FnDeUmwllNDdK+BwCWwCWX9mA/teUP7Od+GH87NDAc9qX5mzN0TjMiD9YixSiH7r2J2ipzpIDoa6/SOWhF7j2TvCBpvROWcwEgvztctHH3P7ybzunr5/+Bzv6GZ0wOV/i8rQe4pHvmfFjO689ymTKfD1fFNOMS64rB7u6fI6b7V5orhLh60CfohEgEBbsQiaBgFyIRFOxCJIKCXYhE6GnByUKhgPHxcH+2zFs8C6mfFORrN7g00WfhwosAcKkczgwDgF+8wzON9tTCGWA3gDiIeNZbNZJ51Xj+FT4vUiLS9u4NjteO8AzBSivcfw8Abj3M5bVyhmebVSdOB8cL85Hsxi28yVrjTEQ6nApLswCQ3xn+vFdlF5dm89u2UtvI/XdS29w7k9Q2PMpluTsHDwTHn/w5TyTtGw7LzpksD2nd2YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIPZXe8vkcdu/ZFbQtnuNZTaURksljPJMon+HZP5MXZ6jtT1/8NbVdvz0sNf3L4gCdU4q8nHqZZ/rNnuDS2+wOLg29WQ/LUI2IXLfnSDgzDAD2j/BzNSZ58cVBIkNZh/dswyJ/zvoyPENwocqzDttvhnsL+sR5OufSEL+uBq4PS8cAsOfQYWqrkcw2ANhRCl8/d9zCi46OHwr7ke/j8qXu7EIkgoJdiERQsAuRCAp2IRJBwS5EIvR0N77tbcy3wx/uz/k8nZfPhd1sRGp0zbV4cspslc9rOV+ShXx4R/hcnieSDDuvadfIcJs7b8k03+G7z2enw7vxWzJFOucS3+jGY+ceo7brSdINABzeFj7f9j6ekFM+zROD2lWe7OJtvo6XLoXrBnqbXwONIt+Nb85z1ajx0uvUVoqoIfViOGnrwE03cz8m3g6Oe5OrHbqzC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhFW0/7pEQCfADDt7rd0x74C4A8AvKtrfMndH1/xWHAUPNwOKdfhtdpGM2FpopGNtGqKSBCVGm/JtHcHbym179B4cPzcEpf54FxyKRDJBQCsxZ+aRofLcmPbR4PjOb5UWLjAk0J8lst8EzNcDpsvhRMy9tf585y5yKU3VPkDyETaRlVbYR8rbX59eESmLFUjCVbneP3CUqQtU7kVfmzDdf6YR289EjY0I+tLLf+PPwPwQGD8T9z99u7XioEuhNhcVgx2d/8ZgNke+CKE2EDW8p79C2b2kpk9YmYj6+aREGJDuNJg/yaAwwBuBzAJ4GvsD83sITM7bmbHl2qRN45CiA3lioLd3afcve3uHQDfAnBX5G+PuftRdz86WOzpR/GFEJdxRcFuZmOX/fppAC+vjztCiI1iNdLbdwF8FMComZ0F8GUAHzWz2wE4gNMA/nA1J8t0MuivhjPEJlq81tnOTLhl0Eh1js7JTfNWPK1F3lbnxpsOUdv+668Ljs+++BqdM2a87Q/yXJbLO38d7l/ikleOZFeVSjy17TdvnKa20TL345qD26jtbCEsAU2d4s9L/yLfB7ZWpOVVm69xjcizjQx/XI0yf7s52w63AAOAUmkLtS02uFxarocf2+w5Xrcutz+cPdhut/kcauni7p8LDH97pXlCiKsLfYJOiERQsAuRCAp2IRJBwS5EIijYhUiE3hac7Djmy2FJ5ifzXO5obQ+P3xNpJdQ/zTO5ik2eyXXHh+6jtj3j4XY8f/XMCTpnvh6WDQGgneMZSs2IZNfvPIOqdjb8uLPbuEx2zUg4Uw4Aam1eCDQ3wFsN3fqR8OesZrkChdnnpqmt3uHSWyfHC0RWyVoNDJCLCgD6eTuvaoE/L53t/FPjNfB55y+EJcf5OV7c8tKr4eKW5Rq/3nRnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCL0VHrzdhONhYmg7dQMz/CpNsMSz/A+Lhndluey1lCk+uKh8XBRSQDYMhiWr+qR4oX1CrcV8jxDqeaReRkueRUa4cdWneUZZRnSSw8AOpF+elMzXN68dPKV4HipyCWoxeIgt/Xzfnr1wSFqK5fDGYKlUS5Fzja4fLXY4s9ZpskLj06eX+LzimGpbyFSNHVgISyJtiJZb7qzC5EICnYhEkHBLkQiKNiFSAQFuxCJ0NPd+C19GXzsQHjn8cIs34l99q1w4sqTp3mSRv81PJmhNMgTJ4ayfNe3uRjepW0b3wEtRxJhilm+/O1s5HXYuK1DaqvNlvlusEdKfBfK3P/mXKSF0htnguOlyP2lEanhdqLFM2hOX+QJNEXS6avQ4Tvn+UgVZGtGkpDmuOJRdq4Y5AbDbcDaeX6uAyPDwfFClreg0p1diERQsAuRCAp2IRJBwS5EIijYhUgEBbsQibCa9k/jAP4cwG4AHQDH3P0bZrYNwPcAHMRyC6jPujvvqwSgmDcc2RM+5b8o7afzxvvOBcf/52tcTnrqNE+Euf3AHmpbeuMtapsjr43ZDtF3AMw1eL27HSUux7SdJ4w0O/yxXfCwLxdLXNqsRRKDhoxfIgNbuf8dkpCDmQU6p6+Py6Vna1wqm2nzZJ3d+bCsVRrg6zE0wP3wKpciLza4j7ksvw6ys2HbLc4TngYXw9dAJlKrbzV39haAP3b3GwHcDeCPzOwmAA8DeMrdrwPwVPd3IcRVyorB7u6T7v589+dFACcB7AXwSQCPdv/sUQCf2ignhRBr5wO9ZzezgwDuAPBLALvcfRJYfkEAsHO9nRNCrB+rDnYzGwTwAwBfdHf+xuu35z1kZsfN7PiFCn9vKITYWFYV7GaWx3Kgf8fdf9gdnjKzsa59DEDwA8rufszdj7r70R2lnn4UXwhxGSsGu5kZlvuxn3T3r19megzAg92fHwTw4/V3TwixXqzmVnsPgN8HcMLMXuiOfQnAVwF838w+D+AMgM+sdKCOd1AnUtS2Is/w+Z0j4VpzF8tc8nruHM+IOznFFcLrIhJPoxBeLu/w18zFGs/W8jqXVmKZVx6RV0Bs/X1FOmXRuZy0sH8XtW2/+QZqy5Kn5sQTP6VzxiNrtW9kB7WhzrPvirmwI/ORenHlGS6T7Y5ImHtGeUupQoY/n/nZ8LV6YJFLy+PDLOuNx9GKwe7uPwfAjnD/SvOFEFcH+gSdEImgYBciERTsQiSCgl2IRFCwC5EIPf2Ui8FgpMiiRQoKjg2HZaN/cGgrnbMQaeFzeo5LK5WIdLGTtIbKFniRylqLy2S1xUVqyzV5EctCvp/a2Iq0pi7QOVva/JON9QW+VrNNLn0Oj4yExyPFMvM1fq69kUy0QuSeZQPh4qKW58fLLHEpb1eOP9cR9RiZOn8+K+Q62BrJlDu8PxwTfc/xtdCdXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EInQU+nNAbiH9QnvRKSmTliWu2kbd//CGM9OKte5zNeKFBQc3R7OvCoOcglwLpKh1mzwwpGtiK2e5T5mLFyockvkZZ3nwwGNBZ49iBr3w8+H+6/tozlVQD4bKXxZ5X7szHIp8hKRWfuGwtIgAHSafLFalTlqW6hzqSyivKFTLwfHx27ixZ8O7Q9fi30kMxPQnV2IZFCwC5EICnYhEkHBLkQiKNiFSIQel3s1dEgiRBu83RFa4Z3prTm+s3vHeLhuHQDMLM5SW2Nqktqa5fCuaWGA7wbXIokfTY8kLURaPLUjSTLWDq9JK+JHIx/J4ADfIbcW96OdJfX1Mvxc7RY/l0d2/ovtcIsnAPBmOKnlfJHvqjf7eG3ATjivBgCQH+B+VCo8uaZAWnbt2L+bzinmwj5mjK+v7uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhBWlNzMbB/DnAHYD6AA45u7fMLOvAPgDAO8WN/uSuz8ePVYmg0J/uPZXtshrezXmwm1wYhLUnmF+vL83z2Wck3NT1HZ+4kxwfKHKm9oudXidtlomUo8tkkDTcv64Mx5+SssRSaZCkpMAIBe5H3Tq/LF16uE1toj0xlpXAUAtxx9zJyLZlckxa308GQoZfq5inmtvnTaX1wZIMhcAXLtrKDg+UuDrUZkJS4ediBy6Gp29BeCP3f15MxsC8JyZPdm1/Ym7/8dVHEMIscmsptfbJIDJ7s+LZnYSwN6NdkwIsb58oPfsZnYQwB0Aftkd+oKZvWRmj5gZTxAWQmw6qw52MxsE8AMAX3T3BQDfBHAYwO1YvvN/jcx7yMyOm9nxixX+EVAhxMayqmA3szyWA/077v5DAHD3KXdvu3sHwLcA3BWa6+7H3P2oux8dLfHPDgshNpYVg93MDMC3AZx0969fNj522Z99GsDL6++eEGK9WM1u/D0Afh/ACTN7oTv2JQCfM7PbsVxa7jSAP1zVGTPh7Lblfx6IkySprJbhbwvyEdli/xiX5d46y+WTBqkV1u7wOXMtbrtofPmHsjwL0Jw/NiMS2zxXyXC+EZHyItly2YhkR48XseUjmY9TkSzAeXD/l8jj3huRAIcjkm52lrfs2pXj1fw+NM4z2A6Phy/wUjUsOQNAnch8nfYapDd3/zkQrBIY1dSFEFcX+gSdEImgYBciERTsQiSCgl2IRFCwC5EIPS84iU749aVe5a1zmMQTy6DySPukwYFw5h0AjG7hUtnshXBLo0XS6ggA5rP89fQXETlphKtr2BKRKQeI9NbM8AMutCLZZhFZKya8ZUlGXyEiKZbiR6SWnHFdsUQed6fJM+UapGgnAPRH1mPrID8mmpHMyEth/xe28OfZSBHWdiRzUHd2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJEKPpTcuDXhEMjAiXxVIvysA8GqkUEZE1to5wI/5/IlwFu/MxIXgOAC0IpltFyJS00IkW67UjkhN5JB9EQnQC/wxZyJFMVmGHQDkcmHZqE36mgHAQps/Z61IIUWPHLPA3I9Ib53IWmVy/OLpgPs/t8R7y2U97EtfJlyIEgCsE76u2pECp7qzC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhF6K72ZIZMPSzL5iBxmxGbZiPuRwnvtMi/kNzbEi1Fuz4ePma9V6ZwtHS5P1SLFHGOFHls5Lq+UifRSjawvIpJXNpIRZxHpMEOkQ48Uy/RI9losHy5vPCMuT66R/sj6DkZugQPGrytyeXThxno1XMg0cpmilAlfpzEJW3d2IRJBwS5EIijYhUgEBbsQiaBgFyIRVtyNN7MigJ8B6Ov+/X919y+b2TYA3wNwEMvtnz7r7pdWOl4mFz5l1iOvOyzRIbobH2knFaldN2g8AeXem/cEx+crfM6vzlyktot1noxRi+yq1iN70x2yJp3I63q0bhmTQgBE8mCQidS8Y2QjO+SR/BP0Z/h1UMqEr4OhHHd+KMNVge2RS64UWZA8+HNdIGvl7cj1QRSgTiQpaDV39jqA+9z9Niy3Z37AzO4G8DCAp9z9OgBPdX8XQlylrBjsvsy7il++++UAPgng0e74owA+tSEeCiHWhdX2Z892O7hOA3jS3X8JYJe7TwJA9/vOjXNTCLFWVhXs7t5299sB7ANwl5ndstoTmNlDZnbczI5fLPP3tkKIjeUD7ca7+xyAnwB4AMCUmY0BQPd7sFOCux9z96PufnQ0UgVGCLGxrBjsZrbDzIa7P/cD+McAXgXwGIAHu3/2IIAfb5STQoi1s5pEmDEAj5pZFssvDt939782s6cBfN/MPg/gDIDPrHikTAYoFImRywzGkieIjAcALdIeBwA6kYcdkzvGSI7MJ27bS+fsynMp5NQUbwk0Veb+X2pFkms64aSQekS6ahl/zB5L1om0csoSWzShJSIBRnJ/MBCRYPuI/32RpJstWZ60MhKR7AYiteuKee5jjixjs8mvgQpJyOlEatCtGOzu/hKAOwLjMwDuX2m+EOLqQJ+gEyIRFOxCJIKCXYhEULALkQgKdiESwWI1wdb9ZGYXALzd/XUUAE8J6x3y473Ij/fy/5sfB9x9R8jQ02B/z4nNjrv70U05ufyQHwn6oX/jhUgEBbsQibCZwX5sE899OfLjvciP9/J3xo9Ne88uhOgt+jdeiETYlGA3swfM7DUzO2Vmm1a7zsxOm9kJM3vBzI738LyPmNm0mb182dg2M3vSzF7vfh/ZJD++Ymbnumvygpl9vAd+jJvZ/zKzk2b2azP7V93xnq5JxI+eromZFc3sGTN7sevHv+uOr2093L2nXwCyAN4AcA2AAoAXAdzUaz+6vpwGMLoJ570XwJ0AXr5s7D8AeLj788MA/v0m+fEVAP+6x+sxBuDO7s9DAH4D4KZer0nEj56uCZYzgQe7P+cB/BLA3Wtdj824s98F4JS7v+nuDQB/ieXilcng7j8DMPu+4Z4X8CR+9Bx3n3T357s/LwI4CWAverwmET96ii+z7kVeNyPY9wJ457Lfz2ITFrSLA/gbM3vOzB7aJB/e5Woq4PkFM3up+2/+hr+duBwzO4jl+gmbWtT0fX4APV6TjSjyuhnBHir1sVmSwD3ufieAfwrgj8zs3k3y42rimwAOY7lHwCSAr/XqxGY2COAHAL7o7ryMT+/96Pma+BqKvDI2I9jPAhi/7Pd9ACY2wQ+4+0T3+zSAH2H5LcZmsaoCnhuNu091L7QOgG+hR2tiZnksB9h33P2H3eGer0nIj81ak+65P3CRV8ZmBPuzAK4zs0NmVgDwe1guXtlTzGzAzIbe/RnAxwC8HJ+1oVwVBTzfvZi6fBo9WBMzMwDfBnDS3b9+mamna8L86PWabFiR117tML5vt/HjWN7pfAPAv9kkH67BshLwIoBf99IPAN/F8r+DTSz/p/N5ANux3Ebr9e73bZvkx38BcALAS92La6wHfnwEy2/lXgLwQvfr471ek4gfPV0TALcC+FX3fC8D+Lfd8TWthz5BJ0Qi6BN0QiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhH+L/DLjzGcDITqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[5])\n",
    "img = images[6]\n",
    "print(labels[57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3022, 32, 32, 3)\n",
      "(3022, 1)\n"
     ]
    }
   ],
   "source": [
    "#find training data\n",
    "#find the cat pictures and labeled with 1 and cars, birds pic are assigned as -1\n",
    "#labels == 3 are cats\n",
    "#labels == 2 are birds\n",
    "#labels == 1 are cars\n",
    "index = np.where((np.array(labels)[0:10000] == 1) |(np.array(labels)[0:10000] == 2)| (np.array(labels)[0:10000] == 3))\n",
    "ind_cat = np.where(np.array(labels)[0:10000] == 3)\n",
    "ind_car_bir = np.where((np.array(labels)[0:10000] == 1)| (np.array(labels)[0:10000] == 2))\n",
    "images1 = np.array(images)\n",
    "images1 = images1[index]\n",
    "labels1 = np.array(labels)\n",
    "labels1[ind_cat] = 1\n",
    "labels1[ind_car_bir] = -1\n",
    "y = labels1[index]\n",
    "y_train = np.reshape(y,(len(y),1))\n",
    "x_train = images1\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(897, 32, 32, 3)\n",
      "(897, 1)\n"
     ]
    }
   ],
   "source": [
    "#find testing data\n",
    "index_t = np.where((np.array(labels)[10001:13000] == 1) |(np.array(labels)[10001:13000] == 2)| (np.array(labels)[10001:13000] == 3))\n",
    "ind_cat_t = np.where(np.array(labels)[10001:13000] == 3)\n",
    "ind_car_bir_t = np.where((np.array(labels)[10001:13000] == 1)| (np.array(labels)[10001:13000] == 2))\n",
    "images2 = np.array(images)\n",
    "images2 = images2[index_t]\n",
    "labels2 = np.array(labels)\n",
    "labels2[ind_cat_t] = 1\n",
    "labels2[ind_car_bir_t] = -1\n",
    "y1 = labels2[index_t]\n",
    "y_test = np.reshape(y1,(len(y1),1))\n",
    "x_test = images2\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3022, 32, 32, 3)\n",
      "(897, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#normalize train data and test data\n",
    "mean = np.mean(x_train, axis = (0,1,2,3))\n",
    "std = np.std(x_train, axis = (0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3022, 3072)\n",
      "(897, 3072)\n"
     ]
    }
   ],
   "source": [
    "#flatten matrix\n",
    "x_train = x_train.reshape(3022, 3072)\n",
    "x_test = x_test.reshape(897,3072)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors of train samples (3022): 1520\n",
      "Errors of test samples (897): 467\n"
     ]
    }
   ],
   "source": [
    "# Least_square solution\n",
    "w0 = np.linalg.inv(x_train.T@x_train)\n",
    "w_opt = w0@x_train.T@y_train\n",
    "y_train_hat = np.sign(x_train@w_opt)\n",
    "error_tran_data = [0 if i[0]==i[1] else 1 for i in np.hstack((y_train_hat, y_train))]\n",
    "print('Errors of train samples (3022): ' +str(sum(error_tran_data)))\n",
    "y_hat = np.sign(x_test@w_opt)\n",
    "error_vec = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_test))]\n",
    "print('Errors of test samples (897): '+ str(sum(error_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]), array([12]))\n",
      "Errors for differnt lamda for training data [[0.01522171 0.02415619 0.06816678 0.10787558 0.12706817 0.17372601\n",
      "  0.19192588 0.21211118 0.22865652 0.24056916 0.27001985 0.2819325\n",
      "  0.31568498]]\n",
      "Errors for differnt lamda for testing data [[0.46822742 0.46265329 0.45707915 0.45819398 0.4671126  0.4671126\n",
      "  0.4671126  0.45930881 0.45373467 0.45596433 0.45039019 0.44593088\n",
      "  0.44147157]]\n",
      "best lamda value 500000.0\n",
      "Number of error in test data  [396.]\n"
     ]
    }
   ],
   "source": [
    "## Ridge Regression\n",
    "# Find the best Lamda for minimum misclassification\n",
    "lamda = np.array([0.5, 1.0, 10.0, 50.0, 100.0, 500.0, 1000.0, 2000.0, 5000.0, 10000.0, 50000.0, 100000.0, 500000.0])\n",
    "N = len(lamda)\n",
    "err = np.zeros((1,N))\n",
    "err0 = np.zeros((1,N))\n",
    "for i in range(N):\n",
    "    lam = lamda[i]\n",
    "    wr0 = np.linalg.inv(x_train.T@x_train + lam*np.identity(len(w0)))\n",
    "    w_rr = wr0@x_train.T@y_train\n",
    "    y_train_h = np.sign(x_train@w_rr)\n",
    "    error_1 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_train_h, y_train))]\n",
    "    arr_err0 = np.array(error_1)\n",
    "    error0 = sum(arr_err0)\n",
    "    err0[:,i] = error0\n",
    "    yr_hat = np.sign(x_test@w_rr)\n",
    "    error_2 = [0 if i[0]==i[1] else 1 for i in np.hstack((yr_hat, y_test))]\n",
    "    arr_err = np.array(error_2)\n",
    "    error = sum(arr_err)\n",
    "    err[:,i] = error\n",
    "min_value = np.amin(err)\n",
    "index = np.where(err == min_value)\n",
    "print(index)\n",
    "print('Errors for differnt lamda for training data', err0/3022)\n",
    "print('Errors for differnt lamda for testing data', err/897)\n",
    "print('best lamda value', lamda[12])\n",
    "print('Number of error in test data ', err[:,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors of training data: 1016\n",
      "Errors of testing data: 305\n"
     ]
    }
   ],
   "source": [
    "## Linear SVM \n",
    "from sklearn.svm import SVC\n",
    "n_test = np.size(y_test)\n",
    "n_train = np.size(y_train)\n",
    "x_train_1 = np.hstack((x_train, np.ones((n_train,1)) ))\n",
    "x_test_1 = np.hstack(( x_test, np.ones((n_test,1)) ))\n",
    "clf = SVC(kernel='linear',C=0.00001)\n",
    "clf.fit(x_train_1, y_train)\n",
    "svm_tr = clf.predict(x_train_1)\n",
    "y_hat_svmt = np.sign(svm_tr).reshape(n_train,1)\n",
    "error_rate0 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat_svmt, y_train))]\n",
    "svm = clf.predict(x_test_1)\n",
    "print('Errors of training data: '+ str(sum(error_rate0)))\n",
    "y_hat_svm = np.sign(svm).reshape(n_test,1)\n",
    "#w_svm = clf.coef_.transpose()\n",
    "#y_hat_svm = np.sign(x_test_1@w_svm)\n",
    "error_rate = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat_svm, y_test))]\n",
    "print('Errors of testing data: '+ str(sum(error_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 1016\n",
      "Errors: 305\n"
     ]
    }
   ],
   "source": [
    "##  rbf SVM \n",
    "clfr = SVC(kernel='rbf',gamma = 0.7,C=0.00001)\n",
    "clfr.fit(x_train_1, y_train)\n",
    "svm_r0 = clfr.predict(x_train_1)\n",
    "y_hat_svmr0 = np.sign(svm_r0).reshape(n_train,1)\n",
    "error_rate_r0 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat_svmr0, y_train))]\n",
    "print('Errors: '+ str(sum(error_rate_r0)))\n",
    "svm_r = clfr.predict(x_test_1)\n",
    "y_hat_svmr = np.sign(svm_r).reshape(n_test,1)\n",
    "#w_svm = clf.coef_.transpose()\n",
    "#y_hat_svm = np.sign(x_test_1@w_svm)\n",
    "error_rate_r = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat_svmr, y_test))]\n",
    "print('Errors: '+ str(sum(error_rate_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66435185 0.66435185 0.66435185 0.66435185 0.66203704 0.66357309\n",
      " 0.66357309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/mmwr/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66435185 0.66435185 0.66435185 0.66435185 0.66203704 0.66357309\n",
      " 0.66357309]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, x_train_1, y_train, cv=7)\n",
    "print(scores)\n",
    "scores_r = cross_val_score(clfr, x_train_1, y_train, cv=7)\n",
    "print(scores_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3073, 1)\n"
     ]
    }
   ],
   "source": [
    "## Neural network \n",
    "# x_train_1 and y_train to train model\n",
    "q = np.shape(y_train)[1] #number of classification problems\n",
    "p = 3072\n",
    "W = np.random.randn(p+1, q);\n",
    "\n",
    "alpha = 0.35 #step size\n",
    "L = 3000 #number of epochs\n",
    "n = 3022 \n",
    "def tanh(_x):\n",
    "    return np.tanh(_x)   ##1/(1+np.exp(-_x)) 465\n",
    "        \n",
    "for epoch in range(L):\n",
    "    ind = np.random.permutation(n)\n",
    "    for i in ind:\n",
    "        # Forward-propagate \n",
    "        Yhat2 = tanh(x_train_1[[i],:]@W) \n",
    "         # Backpropagate\n",
    "        delta = (Yhat2-y_train[[i],:])*(1-np.square(Yhat2))  ###Yhat2*(1-Yhat2)\n",
    "        Wnew = W - alpha*x_train_1[[i],:].T@delta\n",
    "        W = Wnew\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors of training data: 953\n",
      "Errors of testing data: 386\n"
     ]
    }
   ],
   "source": [
    "## Predict on testing data for 2-layer Neural Network\n",
    "Yhatnn = tanh(x_train_1@W)\n",
    "error_nn0 = [0 if i[0]==i[1] else 1 for i in np.hstack((np.round(Yhatnn), y_train))]\n",
    "print('Errors of training data: '+ str(sum(error_nn0)))\n",
    "Yhat2 = tanh(x_test_1@W)\n",
    "error_nn = [0 if i[0]==i[1] else 1 for i in np.hstack((np.round(Yhat2), y_test))]\n",
    "print('Errors of testing data: '+ str(sum(error_nn)))\n",
    "#y_test_nn = y_test/2+0.5\n",
    "#error_nn2 = np.sum(abs(np.round(Yhat2)-y_test_nn))\n",
    "#print('Errors, first classifier:', error_nn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training NN model for X[3022,3072] take me more than 4hrs with 1000 hidden nodes and 1000 epoachs.\n",
    "## hidden nodes = 2/3 inputs +outputs too large for me\n",
    "## Then I stoped the calculation.\n",
    "## I selected 1000 pics in x_train_1 and 300 damples in x_test_1 for NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = x_train_1[0:1000,:]\n",
    "y_train_2 = y_train[0:1000,:]\n",
    "x_test_2 = x_test_1[0:300,:]\n",
    "y_test_2 = y_test[0:300,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, 1)\n",
      "(601, 1)\n",
      "(3073, 600)\n"
     ]
    }
   ],
   "source": [
    "M = 600 #number of hidden nodes\n",
    "\n",
    "## initial weights\n",
    "V3 = np.random.randn(M+1, q); \n",
    "W3 = np.random.randn(p+1, M);\n",
    "print(V3.shape)\n",
    "\n",
    "alpha = 0.35 #step size\n",
    "L = 800 #number of epochs\n",
    "n1 =1000\n",
    "\n",
    "def tanh(_x):\n",
    "    return np.tanh(_x)\n",
    "        \n",
    "for epoch in range(L):\n",
    "    ind = np.random.permutation(n1)\n",
    "    for i in ind:\n",
    "        # Forward-propagate\n",
    "        H = tanh(np.hstack((np.ones((1,1)), x_train_2[[i],:]@W3)))\n",
    "        Yhat0 = tanh(H@V3)\n",
    "         # Backpropagate\n",
    "        delta = (Yhat0-y_train_2[[i],:])*(1-np.square(Yhat0))###Yhat0*(1-Yhat0)\n",
    "        Vnew3 = V3-alpha*H.T@delta\n",
    "        gamma = delta@V3[1:,:].T*(1-np.square(H[:,1:]))  ###H[:,1:]*(1-H[:,1:])\n",
    "        Wnew3 = W3 - alpha*x_train_2[[i],:].T@gamma\n",
    "        V3 = Vnew3\n",
    "        W3 = Wnew3\n",
    "print(V3.shape)\n",
    "print(W3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 154\n"
     ]
    }
   ],
   "source": [
    "## Final predicted labels (on training data)\n",
    "n0 =300\n",
    "H3 = tanh(np.hstack((np.ones((n0,1)), x_test_2@W3)))\n",
    "Yhat3 = tanh(H3@V3)\n",
    "error_nn3 = [0 if i[0]==i[1] else 1 for i in np.hstack((Yhat3, y_test_2))]\n",
    "print('Errors: '+ str(sum(error_nn3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
